{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "\n",
    "def nrnMread(fileName):\n",
    "    f = open(fileName, \"rb\")\n",
    "    nparam = struct.unpack('i', f.read(4))[0]\n",
    "    typeFlg = struct.unpack('i', f.read(4))[0]\n",
    "    return np.fromfile(f,np.double)\n",
    "\n",
    "data_dir ='../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,8): #Nstims\n",
    "    curr_volts = nrnMread(data_dir + '/VHotP' + str(i)  + '.dat')\n",
    "    curr_times = np.genfromtxt(data_dir + '/times' + str(i) + '.csv', delimiter =',')\n",
    "    Nt = int(len(curr_volts)/len(curr_times))\n",
    "    shaped_volts = np.reshape(curr_volts, [Nt,len(curr_times)])\n",
    "    print(shaped_volts.shape)\n",
    "    print(len(curr_volts))\n",
    "    times = shaped_volts.shape[0]\n",
    "    \n",
    "    \n",
    "    for indv in range(1251,1252):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(curr_times)),shaped_volts[indv,:])\n",
    "        plt.title(\"indv\" + str(indv))\n",
    "        plt.ylim(-70,70)\n",
    "\n",
    "#plt.ylim(bottom=ymin) #ymin is your value\n",
    "print(\"population len:\" ,Nt)\n",
    "print(np.max(shaped_volts))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "run_volts_path = '../run_volts_bbp_full_gpu_tuned/'\n",
    "paramsCSV = run_volts_path+'params/params_bbp_full_gpu_tuned_10_based.csv'\n",
    "orig_params = h5py.File(run_volts_path+'params/params_bbp_full_allen_gpu_tune.hdf5', 'r')['orig_full'][0]\n",
    "scores_path = '../scores/'\n",
    "objectives_file = h5py.File('../python/objectives/multi_stim_bbp_full_allen_gpu_tune_18_stims.hdf5', 'r')\n",
    "opt_weight_list = objectives_file['opt_weight_list'][:]\n",
    "opt_stim_name_list = objectives_file['opt_stim_name_list'][:]\n",
    "score_function_ordered_list = objectives_file['ordered_score_function_list'][:]\n",
    "stims_path = run_volts_path+'/stims/allen_data_stims_10000.hdf5'\n",
    "target_volts_path = '../python/target_volts/allen_data_target_volts_10000.hdf5'\n",
    "target_volts_hdf5 = h5py.File(target_volts_path, 'r')\n",
    "opt_stim_list = [e.decode('ascii') for e in opt_stim_name_list]\n",
    "target_volts_list = np.array([target_volts_hdf5[s][:] for s in opt_stim_name_list])\n",
    "\n",
    "for i in range(0,18):\n",
    "    plt.figure()\n",
    "    plt.plot(target_volts_list[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if max(shaped_volts[i,:]) > 20:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "objectives_file = h5py.File('../python/objectives/multi_stim_bbp_full_allen_gpu_tune_18_stims.hdf5', 'r')\n",
    "\n",
    "allen_stim_file = h5py.File('../run_volts_bbp_full_gpu_tuned/stims/allen_data_stims_10000.hdf5', 'r')\n",
    "opt_stim_name_list = objectives_file['opt_stim_name_list'][:]\n",
    "stims = list([e.decode('ascii') for e in opt_stim_name_list])[:]\n",
    "score_function_ordered_list = objectives_file['ordered_score_function_list'][:]\n",
    "for stim in stims:\n",
    "    plt.figure()\n",
    "    plt.plot(allen_stim_file[stim][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score one set of stim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = map_par(0,6)\n",
    "res1 = map_par(6,12)\n",
    "res2 = map_par(12,18)\n",
    "full_res = map_par(0,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.sum(res, axis=1) + np.sum(res1, axis=1) + np.sum(res2, axis=1)\n",
    "print(final)\n",
    "np.sum(full_res, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import bluepyopt as bpop\n",
    "import h5py\n",
    "import score_functions as sf\n",
    "\n",
    "##########SET THESE############\n",
    "nGpus = 6\n",
    "nCpus =  multiprocessing.cpu_count()\n",
    "first_individual = 0\n",
    "last_individual = 1\n",
    "\n",
    "first_stim = 0\n",
    "last_stim = 3\n",
    "###############################\n",
    "objectives = [bpop.objectives.Objective('Weighted score functions')]\n",
    "run_file = './run_model_cori.hoc'\n",
    "run_volts_path = '../run_volts_bbp_full_gpu_tuned/'\n",
    "paramsCSV = run_volts_path+'params/params_bbp_full_gpu_tuned_10_based.csv'\n",
    "orig_params = h5py.File(run_volts_path+'params/params_bbp_full_allen_gpu_tune.hdf5', 'r')['orig_full'][0]\n",
    "scores_path = '../scores/'\n",
    "objectives_file = h5py.File('../python/objectives/multi_stim_bbp_full_allen_gpu_tune_18_stims.hdf5', 'r')\n",
    "opt_weight_list = objectives_file['opt_weight_list'][:]\n",
    "weights = opt_weight_list\n",
    "opt_stim_name_list = objectives_file['opt_stim_name_list'][:]\n",
    "opt_stim_list = [e.decode('ascii') for e in opt_stim_name_list]\n",
    "target_volts_path = '../python/target_volts/allen_data_target_volts_10000.hdf5'\n",
    "target_volts_hdf5 = h5py.File(target_volts_path, 'r')\n",
    "target_volts_list = np.array([target_volts_hdf5[s][:] for s in opt_stim_list])\n",
    "allen_stim_file = h5py.File('../run_volts_bbp_full_gpu_tuned/stims/allen_data_stims_10000.hdf5', 'r')\n",
    "model_dir = '..'\n",
    "data_dir = model_dir+'/Data/'\n",
    "run_dir = '../bin'\n",
    "vs_fn = model_dir + '/Data/VHotP'\n",
    "ntimestep = 10000\n",
    "score_function_ordered_list = objectives_file['ordered_score_function_list'][:]\n",
    "dts = [allen_stim_file[stim.decode(\"utf-8\") + '_dt'][:][0] for stim in opt_stim_name_list] \n",
    "custom_score_functions = [\n",
    "                    'chi_square_normal',\\\n",
    "                    'traj_score_1',\\\n",
    "                    'traj_score_2',\\\n",
    "                    'traj_score_3',\\\n",
    "                    'isi',\\\n",
    "                    'rev_dot_product',\\\n",
    "                    'KL_divergence']\n",
    "\n",
    "# Number of timesteps for the output volt.\n",
    "ntimestep = 10000\n",
    "\n",
    "stim_names = list([e.decode('ascii') for e in opt_stim_name_list])\n",
    "stims = []\n",
    "for stim_name in stim_names:\n",
    "    stims.append(allen_stim_file[stim_name][:])\n",
    "\n",
    "    \n",
    "    \n",
    "def get_first_zero(stim):\n",
    "    \"\"\"Kyung helper function to penalize AP where there should not be one\"\"\"\n",
    "    for i in range(len(stim)-2, -1, -1):\n",
    "        if stim[i] > 0 and stim[i+1] == 0:\n",
    "            return i+1\n",
    "    return None\n",
    "\n",
    "def check_ap_at_zero(stim_ind, volts):\n",
    "    \"\"\"\n",
    "    Kyung function to check if a volt should be penalized for having an AP before there \n",
    "    should be one. Modified to take in \"volts\" as a list of individuals instead of \"volt\"\n",
    "    \"\"\"\n",
    "    stim = stims[stim_ind]\n",
    "    first_zero_ind = get_first_zero(stim)\n",
    "    nindv =volts.shape[0]\n",
    "    checks = np.zeros(len(range(last_individual -first_individual)))\n",
    "    for i in range(first_individual,last_individual):\n",
    "        volt = volts[i,:]\n",
    "        if first_zero_ind:\n",
    "            if np.mean(stim[first_zero_ind:]) == 0:\n",
    "                first_ind_to_check = first_zero_ind + 1000\n",
    "                APs = [True if v > 0 else False for v in volt[first_ind_to_check:]]\n",
    "                if True in APs:\n",
    "                    #return 400 # threshold parameter that I am still tuning\n",
    "                    #print(\"indv:\",i, \"stim ind: \", stim_ind)\n",
    "                    checks[i] = 0\n",
    "    return checks    \n",
    "    \n",
    "    \n",
    "def getVolts(idx):\n",
    "    '''Helper function that gets volts from data and shapes them for a given stim index'''\n",
    "    #print( \"asking for volts:\", idx, \" from rank: \", idx)\n",
    "\n",
    "    fn = vs_fn + str(idx) +  '.dat'    #'.h5'\n",
    "    curr_volts =  nrnMread(fn)\n",
    "    Nt = int(len(curr_volts)/ntimestep)\n",
    "    shaped_volts = np.reshape(curr_volts, [Nt,ntimestep])\n",
    "    return shaped_volts\n",
    "\n",
    "def normalize_scores(curr_scores, transformation,i):\n",
    "    '''changed from hoc eval so that it returns normalized score for list of indvs, not just one\n",
    "    TODO: not sure what transformation[6] does but I changed return statement to fit our \n",
    "    dimensions'''\n",
    "    # transformation contains: [bottomFraction, numStds, newMean, std, newMax, addFactor, divideFactor]\n",
    "    # indices for reference:   [      0       ,    1   ,    2   ,  3 ,    4  ,     5    ,      6      ]\n",
    "    for i in range(len(curr_scores)):\n",
    "        if curr_scores[i] > transformation[4]:\n",
    "            curr_scores[i] = transformation[4]        # Cap newValue to newMax if it is too large\n",
    "    normalized_single_score = (curr_scores + transformation[5])/transformation[6]  # Normalize the new score\n",
    "    if transformation[6] == 0:\n",
    "        #return 1\n",
    "        return 1/0##np.ones(len(self.nindv)) #verify w/ Kyung\n",
    "    return normalized_single_score\n",
    "\n",
    "def eval_stim_sf_pair(perm):\n",
    "    \"\"\" \n",
    "    function that evaluates a stim and score function pair on line 252. Sets i as the actual \n",
    "    index and and mod_i as it's adjusted index (should get 15th target volt but that will \n",
    "    be 7th in the data_volts_list). transform then normalize and then multiply by weight\n",
    "    and then SENT BACK to MAPPER. uses self. for weights, data_volts, and target volts because\n",
    "    it is easy information transfer instead of passing arguments into map.\n",
    "\n",
    "    Arguments\n",
    "    --------------------------------------------------------------------\n",
    "    perm: pair of ints where first is the stim and second is the score function label index\n",
    "    to run\n",
    "\n",
    "    Returns\n",
    "    ---------------------------------------------------------------------\n",
    "    scores: normalized+weighted scores with the shape (nindv, 1), and sends them back to map\n",
    "    to be stacked then summed.\n",
    "\n",
    "    \"\"\"\n",
    "    i = perm[0]\n",
    "    j = perm[1]\n",
    "    counter = 0\n",
    "    curr_data_volt = getVolts(i)#[:,:] \n",
    "    curr_target_volt = target_volts_list[i]\n",
    "    curr_sf = score_function_ordered_list[j].decode('ascii')\n",
    "    curr_weight = weights[len(score_function_ordered_list)*i + j]\n",
    "    transformation = h5py.File(scores_path+opt_stim_list[i]+'_scores.hdf5', 'r')['transformation_const_'+curr_sf][:]\n",
    "    if curr_sf in custom_score_functions:\n",
    "        score = [getattr(sf, curr_sf)(curr_target_volt, curr_data_volt[indv,:], dts[i]) for indv in range(first_individual, last_individual)]\n",
    "    else:\n",
    "        score = sf.eval_efel(curr_sf, curr_target_volt, curr_data_volt[first_individual:last_individual, :], dts[i])\n",
    "    curr_scores =  score #+ check_ap_at_zero(i, curr_data_volt)# here is I am adding penalty\n",
    "    norm_scores = normalize_scores(curr_scores, transformation, i)\n",
    "    for k in range(len(norm_scores)):\n",
    "        if np.isnan(norm_scores[k]):\n",
    "            norm_scores[k] = 1\n",
    "    return norm_scores * curr_weight #+ check_ap_at_zero(i, curr_data_volt)# here is I am adding penalty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def top_SFs(first_stim, last_stim):\n",
    "    \"\"\"\n",
    "    finds scoring functions w/ weight over 50 and pairs them with that stim and sends\n",
    "    them to mapping function so that we will run so many processes\n",
    "    \"\"\"\n",
    "    all_pairs = []\n",
    "    for i in range(first_stim, last_stim):#range(first_stim,last_stim):\n",
    "        sf_len = len(score_function_ordered_list)\n",
    "        curr_weights = weights[sf_len*i: sf_len*i + sf_len] #get range of sfs for this stim\n",
    "        #top_inds = sorted(range(len(curr_weights)), key=lambda i: curr_weights[i], reverse=True)[:10] #finds top ten biggest weight indices\n",
    "        top_inds = np.where(curr_weights > 50)[0] # weights bigger than 50\n",
    "        pairs = list(zip(np.repeat(i,len(top_inds)), [ind for ind in top_inds])) #zips up indices with corresponding stim # to make sure it is refrencing a relevant stim\n",
    "        all_pairs.append(pairs)\n",
    "    flat_pairs = [pair for pairs in all_pairs for pair in pairs] #flatten the list of tuples\n",
    "    return flat_pairs\n",
    "\n",
    "def map_par(first_stim, last_stim):\n",
    "    ''' \n",
    "    This function maps out what stim and score function pairs should be mapped to be evaluated in parallel\n",
    "    first it finds the pairs with the highest weights, the maps them and then adds up the score for each stim\n",
    "    for every individual.\n",
    "\n",
    "\n",
    "    Return\n",
    "    --------------------\n",
    "    2d list of scalar scores for each parameter set w/ shape (nindv,nstims)\n",
    "    '''\n",
    "    #comm.Barrier() # so all workers do mapping at the same time\n",
    "    fxnsNStims = top_SFs(first_stim, last_stim) # 52 stim-sf combinations (stim#,sf#)   \n",
    "    print(fxnsNStims)\n",
    "    ##OPTIONS FOR PARALLELISM FOR NOW\n",
    "    #MPI Version\n",
    "    #executor = MPIPoolExecutor()\n",
    "    #res = executor.map(self.eval_stim_sf_pair, fxnsNStims)\n",
    "    #joblib\n",
    "    #res = Parallel(n_jobs=nCpus, prefer=\"threads\")(delayed(self.eval_stim_sf_pair)(FnS) for FnS in fxnsNStims)\n",
    "    #multiproc / concurrent future\n",
    "    with Pool(nCpus) as p:\n",
    "        res = p.map(eval_stim_sf_pair, fxnsNStims)\n",
    "    res = np.array(list(res)) ########## important: map returns results with shape (# of sf stim pairs, nindv)\n",
    "    res = res[:,:]\n",
    "    print((res.shape), \"res shape\")\n",
    "    prev_sf_idx = 0 \n",
    "    # get first and last stim so we cna iterate through them and make their scores from mapping\n",
    "#     last_stim = (rank+1) * nGpus # ie: 0th rank last_stim = (0+1)*ngpus = ngpus\n",
    "#     first_stim = last_stim - nGpus\n",
    "    for i in range(first_stim, last_stim):  # iterate stims and sum\n",
    "        num_curr_sfs = sum([1 for pair in fxnsNStims if pair[0]==i]) #find how many sf indices for this stim\n",
    "        #print([pair for pair in fxnsNStims if pair[0]==i], \"PAIRS for stim :\" , i)\n",
    "        AP_penalty = check_ap_at_zero(i, getVolts(i))\n",
    "        if i == first_stim:\n",
    "            weighted_sums = np.reshape(np.sum(res[prev_sf_idx:prev_sf_idx+num_curr_sfs, :], axis=0) + AP_penalty ,(-1,1))\n",
    "        else:\n",
    "            #print(np.sum(res[prev_sf_idx:prev_sf_idx+num_sfs, :], axis=0), \"SUM for sfs\", num_sfs, prev_sf_idx  )\n",
    "            curr_stim_sum = np.reshape(np.sum(res[prev_sf_idx:prev_sf_idx+num_curr_sfs, :], axis=0) + AP_penalty, (-1,1))\n",
    "            #print(min(curr_stim_sum[:,0]), \"MIN SCORE FOR STIM\", i)\n",
    "            weighted_sums = np.append(weighted_sums, curr_stim_sum , axis = 1)\n",
    "            #print(min(weighted_sums),\"sums min\")\n",
    "            #print(fxnsNStims[prev_sf_idx:prev_sf_idx+num_curr_sfs], \"FXNS BEING SUMMED at \", i)\n",
    "            #print(prev_sf_idx, num_sfs, len(fxnsNStims))\n",
    "\n",
    "        prev_sf_idx = prev_sf_idx + num_curr_sfs # update score function tracking index\n",
    "    return weighted_sums\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start running neuroGPU\n",
    "full_params = [ 4.56063252e-06, -6.66000000e+01,  4.11901440e+00,  1.72523876e+00,\n",
    "  1.19270009e-01,  1.07414161e+01,  5.02302505e+00,  1.11933994e-01,\n",
    "  8.61572637e-04,  5.08566528e-02,  3.06692579e-03,  1.17344498e+01,\n",
    "  6.00026564e-04,  2.20472008e-03]\n",
    "nGpus = 6\n",
    "\n",
    "from extractModel_mappings_linux import   allparams_from_mapping\n",
    "import subprocess\n",
    "model_dir = '..'\n",
    "data_dir = model_dir+'/Data'\n",
    "run_dir = '../bin'\n",
    "vs_fn = model_dir + '/Data/VHotP'\n",
    "\n",
    "########################################################################################\n",
    "# run this from GPU node and set these values\n",
    "stim_range = np.arange(4) # currently only supports stims 0\n",
    "####################################################################################\n",
    "\n",
    "full_params = np.array(full_params).reshape(1,-1)\n",
    "allparams = allparams_from_mapping(list(full_params))\n",
    "p_objects = []\n",
    "for stim_num in stim_range:\n",
    "    adjusted_ind = stim_num % nGpus\n",
    "    p_objects.append(run_model(adjusted_ind))\n",
    "# for stim_num in stim_range:\n",
    "#     mod_stim_num = stim_num % (nGpus)\n",
    "#     p_objects[mod_stim_num].wait() #wait to get volts output from previous run then read and stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(stim_ind):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------------------------------------------------------\n",
    "    stim_ind: index to send as arg to neuroGPU \n",
    "    params: DEPRECATED remove\n",
    "\n",
    "    Returns\n",
    "    ---------------------------------------------------------\n",
    "    p_object: process object that stops when neuroGPU done\n",
    "    \"\"\"\n",
    "    global_rank = 0\n",
    "    volts_fn = vs_fn + str(stim_ind +(global_rank*nGpus)) + '.dat'\n",
    "    if os.path.exists(volts_fn):\n",
    "        #print(\"removing \", volts_fn, \" from \", global_rank)\n",
    "        os.remove(volts_fn)\n",
    "    cmd = 'ls -l'\n",
    "    !{'cd ..'}\n",
    "    #!{'../bin/neuroGPU'+str(global_rank),str(stim_ind), str(global_rank)}\n",
    "    p_object = subprocess.Popen(['../bin/neuroGPU'+str(global_rank),str(stim_ind), str(global_rank)],\n",
    "                    stdout=subprocess.PIPE, \n",
    "                    stderr=subprocess.STDOUT,  # <-- redirect stderr to stdout\n",
    "                    bufsize=1)\n",
    "    print(p_object, stim_ind)\n",
    "    with p_object.stdout:\n",
    "        for line in iter(p_object.stdout.readline, b''):\n",
    "            print(line),\n",
    "    p_object.wait()\n",
    "    print(p_object.stderr)\n",
    "    return p_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stim_range: #Nstims\n",
    "    curr_volts = nrnMread(data_dir + '/VHotP' + str(i)  + '.dat')\n",
    "    curr_times = np.genfromtxt(data_dir + '/times' + str(i) + '.csv', delimiter =',')\n",
    "    Nt = int(len(curr_volts)/len(curr_times))\n",
    "    shaped_volts = np.reshape(curr_volts, [Nt,len(curr_times)])\n",
    "    print(shaped_volts.shape)\n",
    "    print(len(curr_volts))\n",
    "    times = shaped_volts.shape[0]\n",
    "    \n",
    "    \n",
    "    for indv in range(0,1):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(curr_times)),shaped_volts[indv,:])\n",
    "        plt.title(\"indv\" + str(indv))\n",
    "        plt.ylim(-70,70)\n",
    "\n",
    "#plt.ylim(bottom=ymin) #ymin is your value\n",
    "print(\"population len:\" ,Nt)\n",
    "print(np.max(shaped_volts))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(shaped_volts[0,:].any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
